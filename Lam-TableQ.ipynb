{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+iAtmbNIw3VDVqcBVJWl+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0hTPJWqxL_WT"},"outputs":[],"source":["import numpy as np\n","\n","# Define the states and actions\n","states = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n","numStates = len(states)\n","numActions = 4\n","actions = ['up', 'down', 'right', 'left']\n","\n","# Define the transition matrix\n","R = np.array([\n","    ['A', 'E', 'B', 'A'],\n","    ['B', 'F', 'C', 'A'],\n","    ['C', 'G', 'D', 'B'],\n","    ['D', 'H', 'D', 'C'],\n","    ['A', 'I', 'F', 'E'],\n","    ['B', 'J', 'G', 'E'],\n","    ['C', 'K', 'H', 'F'],\n","    ['D', 'L', 'H', 'G'],\n","    ['E', 'M', 'J', 'I'],\n","    ['F', 'N', 'K', 'I'],\n","    ['G', 'O', 'L', 'J'],\n","    ['H', 'P', 'L', 'K'],\n","    ['I', 'M', 'N', 'M'],\n","    ['J', 'N', 'O', 'M'],\n","    ['K', 'O', 'P', 'N'],\n","    ['L', 'P', 'P', 'O']\n","])\n","listOfHoles = np.array(['F', 'H', 'L', 'M'])"]},{"cell_type":"code","source":["# Define a function to choose an action using epsilon-greedy policy\n","def choose_action(state_index):\n","    #if np.random.uniform() > epsilon:\n","    if np.random.uniform(0, 1) < epsilon:\n","        # Explore: Choose a random action\n","        return np.random.randint(0, numActions)\n","    else:\n","        # Exploit: Choose the action with the highest Q-value\n","        return np.argmax(Q[state_index, :])"],"metadata":{"id":"f6cKIP8RQ5_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","alpha = 0.9    # Learning rate\n","gamma = 0.9    # Discount factor\n","numEpisodes = 8000\n","maxSteps = 99  # Maximum steps per episode\n","epsilon_decay = 0.995  # Epsilon decay rate\n","epsilon_min = 0.01  # Minimum epsilon value"],"metadata":{"id":"JtaSVaZsQ8vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the Q-table with zeros\n","Q = np.zeros((numStates, numActions))\n","epsilon = 0.9  # Exploration rate\n","\n","# Q-learning algorithm\n","for episode in range(numEpisodes):\n","    state = 'A'  # Start from state A\n","    state_index = states.index(state)\n","\n","    for step in range(maxSteps):\n","        action = choose_action(state_index)\n","\n","        next_state = R[state_index, action]\n","        next_state_index = states.index(next_state)\n","\n","        reward = 0\n","        if next_state == 'P':a\n","            reward = 10\n","        if next_state in listOfHoles:\n","            reward = -10\n","\n","        # Q-learning update rule\n","        Q[state_index, action] += alpha * (reward + gamma * np.max(Q[next_state_index, :]) - Q[state_index, action])\n","\n","        # Transition to the next state\n","        state = next_state\n","        state_index = next_state_index\n","\n","        # End the episode if the goal state or a terminal state is reached\n","        if state == 'P':\n","            break\n","\n","    epsilon = max(epsilon_min, epsilon * epsilon_decay)"],"metadata":{"id":"0t1oLzXVeUc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Original Q: \\n \\n\", Q)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDTTMcU_RMxD","executionInfo":{"status":"ok","timestamp":1724332983960,"user_tz":-60,"elapsed":5,"user":{"displayName":"Lam Ngo","userId":"05135763133071598981"}},"outputId":"05115a32-398e-4dd7-e3c1-872d3b94e163"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Q: \n"," \n"," [[ 5.31441     5.9049      5.9049      5.31441   ]\n"," [ 5.9049     -3.439       6.561       5.31441   ]\n"," [ 6.56099996  7.29        5.9049      5.9049    ]\n"," [ 5.90066982 -3.43900367  5.8823546   6.561     ]\n"," [ 5.31441     6.561      -3.439       5.9049    ]\n"," [ 5.9049      7.29        7.29        5.9049    ]\n"," [ 6.561       8.1        -3.439      -3.439     ]\n"," [ 5.83731844 -1.00001721 -3.4390003   7.29      ]\n"," [ 5.9049     -2.71        7.29        6.561     ]\n"," [-3.439       8.1         8.1         6.561     ]\n"," [ 7.29        9.         -1.          7.29      ]\n"," [-3.43900656 10.         -1.          8.09997805]\n"," [ 6.561      -2.71        8.1        -2.71      ]\n"," [ 7.29        8.1         9.         -2.71      ]\n"," [ 8.1         9.         10.          8.1       ]\n"," [ 0.          0.          0.          0.        ]]\n"]}]},{"cell_type":"code","source":["print(\"R matrix: \\n\", R)\n","print(\"List of holes: \", listOfHoles)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p700HXqZf7ht","executionInfo":{"status":"ok","timestamp":1724332986238,"user_tz":-60,"elapsed":284,"user":{"displayName":"Lam Ngo","userId":"05135763133071598981"}},"outputId":"4f51e1a1-7c81-4ca8-a798-50949d7b14dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["R matrix: \n"," [['A' 'E' 'B' 'A']\n"," ['B' 'F' 'C' 'A']\n"," ['C' 'G' 'D' 'B']\n"," ['D' 'H' 'D' 'C']\n"," ['A' 'I' 'F' 'E']\n"," ['B' 'J' 'G' 'E']\n"," ['C' 'K' 'H' 'F']\n"," ['D' 'L' 'H' 'G']\n"," ['E' 'M' 'J' 'I']\n"," ['F' 'N' 'K' 'I']\n"," ['G' 'O' 'L' 'J']\n"," ['H' 'P' 'L' 'K']\n"," ['I' 'M' 'N' 'M']\n"," ['J' 'N' 'O' 'M']\n"," ['K' 'O' 'P' 'N']\n"," ['L' 'P' 'P' 'O']]\n","List of holes:  ['F' 'H' 'L' 'M']\n"]}]},{"cell_type":"markdown","source":["# Testing the optimal policy\n"],"metadata":{"id":"9cWP5hjIS0Aw"}},{"cell_type":"code","source":["# Print the Q-table\n","print(\"Q-table:\")\n","for i, state in enumerate(states):\n","    print(f\"{state}: {Q[i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUt9cahod70d","executionInfo":{"status":"ok","timestamp":1724332988181,"user_tz":-60,"elapsed":271,"user":{"displayName":"Lam Ngo","userId":"05135763133071598981"}},"outputId":"61fc09d9-1c3b-4968-a224-785bbd32635b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Q-table:\n","A: [5.31441 5.9049  5.9049  5.31441]\n","B: [ 5.9049  -3.439    6.561    5.31441]\n","C: [6.56099996 7.29       5.9049     5.9049    ]\n","D: [ 5.90066982 -3.43900367  5.8823546   6.561     ]\n","E: [ 5.31441  6.561   -3.439    5.9049 ]\n","F: [5.9049 7.29   7.29   5.9049]\n","G: [ 6.561  8.1   -3.439 -3.439]\n","H: [ 5.83731844 -1.00001721 -3.4390003   7.29      ]\n","I: [ 5.9049 -2.71    7.29    6.561 ]\n","J: [-3.439  8.1    8.1    6.561]\n","K: [ 7.29  9.   -1.    7.29]\n","L: [-3.43900656 10.         -1.          8.09997805]\n","M: [ 6.561 -2.71   8.1   -2.71 ]\n","N: [ 7.29  8.1   9.   -2.71]\n","O: [ 8.1  9.  10.   8.1]\n","P: [0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["# Derive the optimal policy from the Q-table\n","optimal_policy = {}\n","for i, state in enumerate(states):\n","    optimal_action_index = np.argmax(Q[i])\n","    optimal_policy[state] = actions[optimal_action_index]\n","\n","# Print the optimal policy\n","print(\"\\nOptimal Policy:\")\n","for state, action in optimal_policy.items():\n","    print(f\"{state}: {action}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSXtL04Wd3kT","executionInfo":{"status":"ok","timestamp":1724332990634,"user_tz":-60,"elapsed":242,"user":{"displayName":"Lam Ngo","userId":"05135763133071598981"}},"outputId":"66bde5c5-9243-4460-ba24-5c2101b15a3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Optimal Policy:\n","A: down\n","B: right\n","C: down\n","D: left\n","E: down\n","F: down\n","G: down\n","H: left\n","I: right\n","J: down\n","K: down\n","L: down\n","M: right\n","N: right\n","O: right\n","P: up\n"]}]}]}